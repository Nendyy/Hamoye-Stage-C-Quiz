{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0712bf48",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center;'> Hamoye Stage C Quiz Questions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffeb6640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d7865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset to a dataframe\n",
    "data = pd.read_csv('Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf44043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41352c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63c0a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tau1    10000 non-null  float64\n",
      " 1   tau2    10000 non-null  float64\n",
      " 2   tau3    10000 non-null  float64\n",
      " 3   tau4    10000 non-null  float64\n",
      " 4   p1      10000 non-null  float64\n",
      " 5   p2      10000 non-null  float64\n",
      " 6   p3      10000 non-null  float64\n",
      " 7   p4      10000 non-null  float64\n",
      " 8   g1      10000 non-null  float64\n",
      " 9   g2      10000 non-null  float64\n",
      " 10  g3      10000 non-null  float64\n",
      " 11  g4      10000 non-null  float64\n",
      " 12  stab    10000 non-null  float64\n",
      " 13  stabf   10000 non-null  object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fff1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0038cf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[ 'stabf' ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70735272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessar libraries and packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b90cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['stab', 'stabf'], axis=1)\n",
    "y = data['stabf']\n",
    "\n",
    "# Split the data into train and test sets with a random state of 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Apply standard scaling to the train and test sets\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "x_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcbcc0",
   "metadata": {},
   "source": [
    "> Use label encoder to transform the 'stable' and 'unstable' variables in stabf column  to 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86fe4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'stabf' column in the train set\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Transform the 'stabf' column in the test set\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637cd4d",
   "metadata": {},
   "source": [
    "### Answering the quiz questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f802a17a",
   "metadata": {},
   "source": [
    "> What is the accuracy on the test set using the random forest classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d988a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9290\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=1)\n",
    "rf_clf.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_pred = rf_clf.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "rf_accuracy = accuracy_score(y_test_encoded, rf_pred)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83570b46",
   "metadata": {},
   "source": [
    "> What is the accuracy on the test set using the XGboost classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43be81a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(random_state=1)\n",
    "xgb_clf.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_pred = xgb_clf.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "xgb_accuracy = accuracy_score(y_test_encoded, xgb_pred)\n",
    "print(\"XGBoost Accuracy:\", xgb_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59ca3b",
   "metadata": {},
   "source": [
    "> What is the accuracy on the test set using the LGBM classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcba3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "# Train a LightGBM model\n",
    "lgb_clf = lgb.LGBMClassifier(random_state=1)\n",
    "lgb_clf.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lgb_pred = lgb_clf.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "lgb_accuracy = accuracy_score(y_test_encoded, lgb_pred)\n",
    "print(f\"LightGBM Accuracy: {lgb_accuracy:.4f}\")\n",
    "#print(f\"Mean Absolute Error: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8ab52",
   "metadata": {},
   "source": [
    "> Using the ExtraTreesClassifier as your estimator with cv=5, n_iter=10, scoring = 'accuracy', n_jobs = -1, verbose = 1 and random_state = 1. What are the best hyperparameters from the randomized search CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b4c58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the ExtraTreesClassifier estimator\n",
    "estimator = ExtraTreesClassifier(random_state=1)\n",
    "\n",
    "#combination of hyperparameters\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "\n",
    "# Define the hyperparameter grid for RandomizedSearchCV\n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "                       'min_samples_split': min_samples_split,\n",
    "\n",
    "                       'max_features': max_features}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "027df314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Hyperparameters: {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator, hyperparameter_grid, cv=5, n_iter=10, scoring='accuracy',\n",
    "                                   n_jobs=-1, verbose=1, random_state=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the data\n",
    "random_search.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eecaac2",
   "metadata": {},
   "source": [
    "> Train a new ExtraTreesClassifier Model with the new Hyperparameters from the RandomizedSearchCV (with random_state = 1). Is the accuracy of the new optimal model higher or lower than the initial ExtraTreesClassifier model with no hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21f99ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Accuracy: 0.928\n"
     ]
    }
   ],
   "source": [
    "# Train an Extra Trees Classifier\n",
    "et_clf = ExtraTreesClassifier(random_state=1)\n",
    "et_clf.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test set\n",
    "et_pred = et_clf.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "et_accuracy = accuracy_score(y_test_encoded, et_pred)\n",
    "print(\"Extra Trees Accuracy:\", et_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6ebfb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the New Optimal ExtraTreesClassifier Model: 0.927\n"
     ]
    }
   ],
   "source": [
    "# Create the new ExtraTreesClassifier with the optimal hyperparameters\n",
    "new_et_clf = ExtraTreesClassifier(random_state=1, **random_search.best_params_)\n",
    "\n",
    "# Fit the new ExtraTreesClassifier on the training data\n",
    "new_et_clf.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test set using the new model\n",
    "new_et_pred = new_et_clf.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate the accuracy of the new model\n",
    "new_et_accuracy = accuracy_score(y_test_encoded, new_et_pred)\n",
    "print(\"Accuracy of the New Optimal ExtraTreesClassifier Model:\", new_et_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756a600",
   "metadata": {},
   "source": [
    "> The accuracy of the ExtraTreesClassifier without hyperparameter tuning is 0.928 (93%) while that of the classifier with hyperparameter tuning is 0.927 (93%), So we can say that there is no change in the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72667545",
   "metadata": {},
   "source": [
    "> Find the feature importance using the optimal ExtraTreesClassifier model. Which features are the most and least important respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71974b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Importance\n",
      "1     tau2    0.140508\n",
      "0     tau1    0.137240\n",
      "3     tau4    0.135417\n",
      "2     tau3    0.134680\n",
      "10      g3    0.113063\n",
      "11      g4    0.109541\n",
      "9       g2    0.107578\n",
      "8       g1    0.102562\n",
      "6       p3    0.005429\n",
      "5       p2    0.005337\n",
      "7       p4    0.004962\n",
      "4       p1    0.003684\n",
      "Feature with the most importance: tau2\n",
      "Feature with the least importance: p1\n"
     ]
    }
   ],
   "source": [
    "# Get the feature importances from the optimal ExtraTreesClassifier model\n",
    "feature_importances = new_et_clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display the feature importances\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(importance_df)\n",
    "\n",
    "# Print the feature with the most importance\n",
    "print(\"Feature with the most importance:\", importance_df.iloc[0]['Feature'])\n",
    "\n",
    "# Print the feature with the highest weight\n",
    "print(\"Feature with the least importance:\", importance_df.iloc[-1]['Feature'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
